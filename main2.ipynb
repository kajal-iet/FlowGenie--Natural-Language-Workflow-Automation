{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0803bb",
   "metadata": {},
   "source": [
    "# FlowGenie: Natural-Language Workflow Automation Designer ðŸ§ âš™ï¸\n",
    "\n",
    "**Track:** Enterprise Agents  \n",
    "**Tech:** Google ADK (google-adk), Gemini, Multi-Agent, Tools, Evaluation, Sessions\n",
    "\n",
    "This notebook implements **FlowGenie**, a multi-agent system that turns natural language requests into **structured automation workflows** (JSON). \n",
    "\n",
    "**Example:**  \n",
    "> \"When a new lead fills a form, log it in a sheet and send me a summary email.\"\n",
    "\n",
    "FlowGenie:\n",
    "1. **Plans** the workflow (triggers, actions, data flow)  \n",
    "2. **Evaluates** the quality & safety of the plan  \n",
    "3. **Simulates execution** of the workflow  \n",
    "4. Optionally **routes actions to tool agents** (Slack, Sheets, Gmail, Calendar â€“ stubbed)  \n",
    "5. Returns a structured JSON workflow that a no-code platform (Zapier/IFTTT/Make/etc.) could implement.\n",
    "\n",
    "This directly targets **enterprise productivity**: automating repetitive workflows without requiring users to write code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "id": "e20a0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup & Dependencies\n",
    "\n",
    "!pip install -q python-dotenv\n",
    "!pip install -q -U google-adk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "id": "853d3515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found in environment. Please set it before running.\")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "id": "d0db1681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment and imports ready. Using model: gemini-2.5-flash-lite\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "\n",
    "from google.genai import types\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools import google_search  # just to show built-in tool usage\n",
    "\n",
    "print(\"âœ… Environment and imports ready. Using model:\", MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "id": "8e184b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real tools: shared imports & auth helpers\n",
    "\n",
    "!pip install -q google-api-python-client google-auth google-auth-httplib2 requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "id": "3bcc7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import base64\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "import requests\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "USE_REAL_APIS = os.getenv(\"USE_REAL_APIS\", \"true\").lower() == \"true\"\n",
    "\n",
    "def get_service_account_credentials(scopes: List[str]):\n",
    "    \"\"\"\n",
    "    Build service account credentials from GOOGLE_SERVICE_ACCOUNT_JSON.\n",
    "    Accepts either:\n",
    "      - a JSON string with double quotes,\n",
    "      - a path to a JSON file (GOOGLE_SERVICE_ACCOUNT_JSON points to a file),\n",
    "      - or a Python literal string (fallback via ast.literal_eval).\n",
    "    If GMAIL_SENDER_EMAIL is set, we also use it as the delegated user\n",
    "    (for Gmail / Calendar when domain-wide delegation is configured).\n",
    "    \"\"\"\n",
    "    json_str = os.getenv(\"GOOGLE_SERVICE_ACCOUNT_JSON\")\n",
    "    if not json_str:\n",
    "        raise RuntimeError(\"GOOGLE_SERVICE_ACCOUNT_JSON env var not set.\")\n",
    "\n",
    "    # If the env value looks like a path to a file, load it\n",
    "    if os.path.exists(json_str):\n",
    "        with open(json_str, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_str = f.read()\n",
    "\n",
    "    # Try strict JSON first, then fallback to ast.literal_eval for Python-style dicts\n",
    "    try:\n",
    "        info = json.loads(json_str)\n",
    "    except Exception:\n",
    "        try:\n",
    "            import ast\n",
    "            info = ast.literal_eval(json_str)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                \"Failed to parse GOOGLE_SERVICE_ACCOUNT_JSON. \"\n",
    "                \"Provide a valid JSON string (double quotes) or a path to a JSON file.\"\n",
    "            ) from e\n",
    "\n",
    "    creds = service_account.Credentials.from_service_account_info(info, scopes=scopes)\n",
    "\n",
    "    # Optional: domain-wide delegation for Workspace\n",
    "    delegated_user = os.getenv(\"GMAIL_SENDER_EMAIL\")\n",
    "    if delegated_user:\n",
    "        creds = creds.with_subject(delegated_user)\n",
    "\n",
    "    return creds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "id": "41efef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Workflow Representation\n",
    "\n",
    "WORKFLOW_JSON_GUIDE = \"\"\"\n",
    "You are designing an automation workflow.\n",
    "\n",
    "Always output a JSON object with this structure:\n",
    "\n",
    "{\n",
    "  \"name\": \"<short human-friendly name>\",\n",
    "  \"trigger\": {\n",
    "    \"type\": \"<trigger_type>\",\n",
    "    \"source\": \"<where the event originates>\",\n",
    "    \"schedule\": \"<cron or time-based trigger, or null>\",\n",
    "    \"conditions\": [\n",
    "      \"<optional condition 1>\",\n",
    "      \"<optional condition 2>\"\n",
    "    ]\n",
    "  },\n",
    "  \"actions\": [\n",
    "    {\n",
    "      \"type\": \"<action_type>\",\n",
    "      \"target\": \"<system or destination>\",\n",
    "      \"description\": \"<what this step does>\",\n",
    "      \"inputs\": [\n",
    "        \"<critical input or data needed>\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Use lowercase snake_case for types when possible.\n",
    "- If something is unknown, put null or an empty list instead of guessing wildly.\n",
    "- The workflow should be as simple as possible while still solving the user's request.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "from google.adk.tools import load_memory\n",
    "\n",
    "# Simple in-notebook memory store (compatibility layer for tests/debugging).\n",
    "MEMORY_ENTRIES = {}\n",
    "\n",
    "def simple_load_memory(payload):\n",
    "    \"\"\"\n",
    "    Accepts payload like {'query': '...'} or a plain string.\n",
    "    Returns a dict with 'memories' list so planner's load_memory call can find items.\n",
    "    \"\"\"\n",
    "    q = None\n",
    "    user = globals().get(\"USER_ID\", None)\n",
    "\n",
    "    if isinstance(payload, dict):\n",
    "        q = payload.get(\"query\") or payload.get(\"q\") or payload.get(\"text\")\n",
    "        user = payload.get(\"user_id\") or user\n",
    "    else:\n",
    "        q = str(payload)\n",
    "\n",
    "    entries = MEMORY_ENTRIES.get(user, [])\n",
    "    if not q:\n",
    "        return {\"memories\": entries}\n",
    "\n",
    "    ql = q.lower().strip()\n",
    "    matches = [e for e in entries if ql in e.lower()]\n",
    "    return {\"memories\": matches}\n",
    "\n",
    "# Register both the built-in load_memory and the simple compatibility tool.\n",
    "\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "id": "b016d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = Agent(\n",
    "    name=\"workflow_planner\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Plans automation workflows from natural-language requests.\",\n",
    "    instruction=(\n",
    "        \"You are an expert workflow automation designer.\\n\"\n",
    "        \"Given a user's natural-language request, generate exactly ONE automation workflow.\\n\"\n",
    "        \"DO NOT return a list of workflows.\\n\"\n",
    "        \"DO NOT return multiple possible interpretations.\\n\"\n",
    "        \"Return ONLY ONE JSON object that follows this schema:\\n\"\n",
    "        f\"{WORKFLOW_JSON_GUIDE}\\n\\n\"\n",
    "        \"Respond with ONLY the JSON object. Never return a list or surrounding quotes.\"\n",
    "        \"If context is unclear or missing, call load_memory() first to retrieve previous details.\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "id": "b5264f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.tools import load_memory\n",
    "\n",
    "planner_agent.tools = [load_memory, simple_load_memory]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "id": "73e60b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_agent = Agent(\n",
    "    name=\"workflow_evaluator\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Evaluates workflow quality, safety, and completeness.\",\n",
    "    instruction=(\n",
    "        \"You are evaluating an automation workflow JSON.\\n\"\n",
    "        \"Check for:\\n\"\n",
    "        \"- Clarity of trigger\\n\"\n",
    "        \"- Completeness of actions\\n\"\n",
    "        \"- Edge cases and failure modes\\n\"\n",
    "        \"- Privacy or safety concerns\\n\\n\"\n",
    "        \"Return a JSON object with:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"overall_score\": <0-10>,\\n'\n",
    "        '  \"verdict\": \"<ACCEPT or IMPROVE>\",\\n'\n",
    "        '  \"strengths\": [\"...\"],\\n'\n",
    "        '  \"risks\": [\"...\"],\\n'\n",
    "        '  \"suggested_changes\": [\"...\"]\\n'\n",
    "        \"}\\n\"\n",
    "        \"Be concise but specific. Respond with ONLY JSON.\"\n",
    "        \"If referenced entities are unclear (names, IDs, preferences), call load_memory() first to retrieve missing details.\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "id": "efb0c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_agent.tools = [load_memory, simple_load_memory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_workflow_execution(workflow: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simulate execution of a workflow.\n",
    "\n",
    "    This does NOT call real APIs, but:\n",
    "    - iterates through actions,\n",
    "    - marks each as 'success',\n",
    "    - returns an execution log.\n",
    "    \"\"\"\n",
    "    name = workflow.get(\"name\", \"unnamed_workflow\")\n",
    "    actions = workflow.get(\"actions\", [])\n",
    "\n",
    "    log = []\n",
    "    for idx, action in enumerate(actions, start=1):\n",
    "        log.append(\n",
    "            {\n",
    "                \"step\": idx,\n",
    "                \"type\": action.get(\"type\"),\n",
    "                \"target\": action.get(\"target\"),\n",
    "                \"status\": \"success\",\n",
    "                \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "                \"note\": f\"Simulated execution of step {idx}\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"workflow_name\": name,\n",
    "        \"total_steps\": len(actions),\n",
    "        \"completed_steps\": len(actions),\n",
    "        \"status\": \"completed\" if actions else \"no_actions\",\n",
    "        \"log\": log,\n",
    "    }\n",
    "\n",
    "\n",
    "# executor_agent = Agent(\n",
    "#     name=\"workflow_executor\",\n",
    "#     model=MODEL_NAME,\n",
    "#     description=\"Simulates running automation workflows and validates feasibility.\",\n",
    "#     instruction=(\n",
    "#         \"You are responsible for simulating the execution of a workflow JSON.\\n\"\n",
    "#         \"ALWAYS call the tool exactly as:\\n\"\n",
    "#         \"simulate_workflow_execution(workflow=<the full workflow JSON>)\\n\\n\"\n",
    "#         \"After the tool call finishes, return ONLY a JSON object with this structure:\\n\"\n",
    "#         \"{\\n\"\n",
    "#         '  \"tool_result\": <raw tool result>,\\n'\n",
    "#         '  \"summary\": \"<short human-friendly summary of what the workflow did>\"\\n'\n",
    "#         \"}\\n\"\n",
    "#         \"Do not wrap the JSON in quotes, code blocks or backticks.\"\n",
    "#     ),\n",
    "#     tools=[simulate_workflow_execution],\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "id": "7acd7da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "id": "c8d48149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Real tools (Slack, Sheets, Gmail, Calendar)\n",
    "# They will call real APIs when USE_REAL_APIS=true and env vars are present,\n",
    "# otherwise they behave like safe no-ops with clear logs.\n",
    "\n",
    "# ...existing code...\n",
    "def slack_send_notification(channel: str, message: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Send a Slack notification via webhook. Returns diagnostic dict on failure.\n",
    "    Uses SLACK_WEBHOOK_URL from environment.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    from urllib.parse import urlparse\n",
    "\n",
    "    webhook_url = os.getenv(\"SLACK_WEBHOOK_URL\")\n",
    "    if not USE_REAL_APIS or not webhook_url:\n",
    "        print(f\"[SLACK NO-OP] Channel={channel} | Message={message}\")\n",
    "        return {\n",
    "            \"channel\": channel,\n",
    "            \"message\": message,\n",
    "            \"status\": \"skipped\",\n",
    "            \"reason\": \"USE_REAL_APIS is false or SLACK_WEBHOOK_URL not set\",\n",
    "        }\n",
    "\n",
    "    # Validate URL has scheme + netloc\n",
    "    try:\n",
    "        parsed = urlparse(webhook_url)\n",
    "        if not parsed.scheme or not parsed.netloc:\n",
    "            raise ValueError(\"invalid\")\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"channel\": channel,\n",
    "            \"message\": message,\n",
    "            \"status\": \"error\",\n",
    "            \"reason\": \"SLACK_WEBHOOK_URL is malformed or missing scheme (must start with http:// or https://)\",\n",
    "            \"webhook_preview\": (webhook_url[:50] + \"...\") if webhook_url else \"<empty>\",\n",
    "        }\n",
    "\n",
    "    payload = {\"text\": message}\n",
    "    try:\n",
    "        resp = requests.post(webhook_url, json=payload, timeout=10)\n",
    "    except requests.RequestException as e:\n",
    "        return {\n",
    "            \"channel\": channel,\n",
    "            \"message\": message,\n",
    "            \"status\": \"error\",\n",
    "            \"reason\": f\"request_exception: {type(e).__name__}: {e}\",\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"channel\": channel,\n",
    "        \"message\": message,\n",
    "        \"http_status\": resp.status_code,\n",
    "        \"status\": \"sent\" if resp.status_code in (200, 204) else \"error\",\n",
    "        \"response_text\": resp.text[:200],\n",
    "    }\n",
    "# ...existing code...\n",
    "\n",
    "\n",
    "def sheets_append_row(row_values: List[str]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Append a row to Google Sheet.\n",
    "    spreadsheet_id and sheet_name are loaded from environment.\n",
    "    \"\"\"\n",
    "    # Load from environment\n",
    "    spreadsheet_id = os.getenv(\"SHEETS_SPREADSHEET_ID\")\n",
    "    sheet_name = os.getenv(\"SHEETS_TAB_NAME\", \"Sheet1\")\n",
    "\n",
    "    if not USE_REAL_APIS:\n",
    "        print(f\"[SHEETS NO-OP] Spreadsheet={spreadsheet_id} | Sheet={sheet_name} | Row={row_values}\")\n",
    "        return {\n",
    "            \"spreadsheet_id\": spreadsheet_id,\n",
    "            \"sheet_name\": sheet_name,\n",
    "            \"row_values\": row_values,\n",
    "            \"status\": \"skipped\",\n",
    "            \"reason\": \"USE_REAL_APIS is false\",\n",
    "        }\n",
    "\n",
    "    scopes = [\"https://www.googleapis.com/auth/spreadsheets\"]\n",
    "    creds = get_service_account_credentials(scopes)\n",
    "    service = build(\"sheets\", \"v4\", credentials=creds)\n",
    "\n",
    "    range_ = f\"{sheet_name}!A1\"\n",
    "    body = {\"values\": [row_values]}\n",
    "\n",
    "    result = (\n",
    "        service.spreadsheets()\n",
    "        .values()\n",
    "        .append(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=range_,\n",
    "            valueInputOption=\"USER_ENTERED\",\n",
    "            insertDataOption=\"INSERT_ROWS\",\n",
    "            body=body,\n",
    "        )\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"spreadsheet_id\": spreadsheet_id,\n",
    "        \"sheet_name\": sheet_name,\n",
    "        \"row_values\": row_values,\n",
    "        \"status\": \"appended\",\n",
    "        \"updates\": result.get(\"updates\", {}),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def gmail_send_email(to: str, subject: str, body: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Send an email using Gmail API and a service account with domain-wide delegation.\n",
    "    Uses GMAIL_SENDER_EMAIL as 'from' and delegated user.\n",
    "    \"\"\"\n",
    "    sender = os.getenv(\"GMAIL_SENDER_EMAIL\") or \"kajal1202patel@gmail.com\"\n",
    "\n",
    "    if not USE_REAL_APIS:\n",
    "        print(f\"[GMAIL NO-OP] From={sender} | To={to} | Subject={subject}\")\n",
    "        return {\n",
    "            \"from\": sender,\n",
    "            \"to\": to,\n",
    "            \"subject\": subject,\n",
    "            \"status\": \"skipped\",\n",
    "            \"reason\": \"USE_REAL_APIS is false\",\n",
    "        }\n",
    "\n",
    "    scopes = [\"https://www.googleapis.com/auth/gmail.send\"]\n",
    "    creds = get_service_account_credentials(scopes)\n",
    "    service = build(\"gmail\", \"v1\", credentials=creds)\n",
    "\n",
    "    msg = MIMEText(body)\n",
    "    msg[\"to\"] = to\n",
    "    msg[\"from\"] = sender\n",
    "    msg[\"subject\"] = subject\n",
    "\n",
    "    raw = base64.urlsafe_b64encode(msg.as_bytes()).decode(\"utf-8\")\n",
    "    message = {\"raw\": raw}\n",
    "\n",
    "    sent = (\n",
    "        service.users()\n",
    "        .messages()\n",
    "        .send(userId=\"me\", body=message)\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"from\": sender,\n",
    "        \"to\": to,\n",
    "        \"subject\": subject,\n",
    "        \"status\": \"sent\",\n",
    "        \"message_id\": sent.get(\"id\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def calendar_create_event(calendar_id: str, title: str, start_time: str, end_time: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a calendar event using Calendar API.\n",
    "    Uses CALENDAR_ID from environment by default.\n",
    "    \"\"\"\n",
    "    if not USE_REAL_APIS:\n",
    "        print(f\"[CALENDAR NO-OP] Calendar={calendar_id} | Title={title} | {start_time} -> {end_time}\")\n",
    "        return {\n",
    "            \"calendar_id\": calendar_id,\n",
    "            \"title\": title,\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time,\n",
    "            \"status\": \"skipped\",\n",
    "            \"reason\": \"USE_REAL_APIS is false\",\n",
    "        }\n",
    "\n",
    "    scopes = [\"https://www.googleapis.com/auth/calendar\"]\n",
    "    creds = get_service_account_credentials(scopes)\n",
    "    service = build(\"calendar\", \"v3\", credentials=creds)\n",
    "\n",
    "    event = {\n",
    "        \"summary\": title,\n",
    "        \"start\": {\"dateTime\": start_time},\n",
    "        \"end\": {\"dateTime\": end_time},\n",
    "    }\n",
    "\n",
    "    created = (\n",
    "        service.events()\n",
    "        .insert(calendarId=calendar_id, body=event)\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"calendar_id\": calendar_id,\n",
    "        \"title\": title,\n",
    "        \"start_time\": start_time,\n",
    "        \"end_time\": end_time,\n",
    "        \"status\": \"created\",\n",
    "        \"event_id\": created.get(\"id\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "id": "701db7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test sheets_append_row directly\n",
    "# spreadsheet_id = os.getenv(\"SHEETS_SPREADSHEET_ID\")\n",
    "# sheet_name = os.getenv(\"SHEETS_TAB_NAME\", \"Sheet1\")\n",
    "# row_values = [\"0012\", \"Rajesh\", \"Login Issue\", \"Unable to log in\"]\n",
    "\n",
    "# print(f\"Testing sheets_append_row with:\")\n",
    "# print(f\"  spreadsheet_id: {spreadsheet_id}\")\n",
    "# print(f\"  sheet_name: {sheet_name}\")\n",
    "# print(f\"  row_values: {row_values}\")\n",
    "# print()\n",
    "\n",
    "# result = sheets_append_row(spreadsheet_id, sheet_name, row_values)\n",
    "# print(\"Result:\")\n",
    "# print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "id": "8dd092ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Tool Agents that wrap the real tools.\n",
    "# These will be used as \"agent tools\" by the executor (A2A-style).\n",
    "\n",
    "slack_agent = Agent(\n",
    "    name=\"slack_agent\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Agent that sends Slack notifications via a tool.\",\n",
    "    instruction=(\n",
    "        \"You send notifications to Slack channels.\\n\"\n",
    "        \"ALWAYS call the tool slack_send_notification(channel=<channel>, message=<message>).\\n\"\n",
    "        \"Return ONLY the JSON returned by the tool, no extra text.\"\n",
    "    ),\n",
    "    tools=[slack_send_notification],\n",
    ")\n",
    "\n",
    "sheets_agent = Agent(\n",
    "    name=\"sheets_agent\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Agent that appends rows to a Google Sheet via a tool.\",\n",
    "    instruction=(\n",
    "        \"You receive a request to append data to a spreadsheet.\\n\"\n",
    "        \"Extract ONLY the row_values from the input.\\n\"\n",
    "        \"ALWAYS call sheets_append_row(row_values=<list of strings>).\\n\"\n",
    "        \"The spreadsheet_id and sheet_name will be loaded from environment \"\n",
    "        \"variables inside the tool.\\n\"\n",
    "        \"Return ONLY the JSON returned by the tool.\"\n",
    "    ),\n",
    "    tools=[sheets_append_row],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "gmail_agent = Agent(\n",
    "    name=\"gmail_agent\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Agent that sends emails via a tool.\",\n",
    "    instruction=(\n",
    "        \"You send emails.\\n\"\n",
    "        \"ALWAYS call gmail_send_email(to=<email>, subject=<subject>, body=<body>).\\n\"\n",
    "        \"Return ONLY the JSON returned by the tool.\"\n",
    "    ),\n",
    "    tools=[gmail_send_email],\n",
    ")\n",
    "\n",
    "calendar_agent = Agent(\n",
    "    name=\"calendar_agent\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Agent that creates calendar events via a tool.\",\n",
    "    instruction=(\n",
    "        \"You create calendar events.\\n\"\n",
    "        \"ALWAYS call calendar_create_event(calendar_id=<calendar_id>, title=<title>, \"\n",
    "        \"start_time=<start>, end_time=<end>).\\n\"\n",
    "        \"Return ONLY the JSON returned by the tool.\"\n",
    "    ),\n",
    "    tools=[calendar_create_event],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "id": "c33ab114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sessions + runners (planner/evaluator/tool-agents) initialized!\n"
     ]
    }
   ],
   "source": [
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.tools import load_memory\n",
    "\n",
    "# 5. Session + Runners\n",
    "\n",
    "session_service = InMemorySessionService()\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "\n",
    "memory_service = InMemoryMemoryService()\n",
    "\n",
    "APP_NAME = \"flowgenie\"\n",
    "USER_ID = \"demo_user\"\n",
    "SESSION_ID = \"flowgenie_session_001\"\n",
    "\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID,\n",
    "    state={},\n",
    ")\n",
    "\n",
    "planner_runner = Runner(\n",
    "    agent=planner_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service\n",
    ")\n",
    "\n",
    "evaluator_runner = Runner(\n",
    "    agent=evaluator_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service\n",
    ")\n",
    "\n",
    "# executor_runner will be created AFTER we redefine executor_agent below.\n",
    "\n",
    "slack_runner = Runner(\n",
    "    agent=slack_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "sheets_runner = Runner(\n",
    "    agent=sheets_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "gmail_runner = Runner(\n",
    "    agent=gmail_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "calendar_runner = Runner(\n",
    "    agent=calendar_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "print(\"âœ… Sessions + runners (planner/evaluator/tool-agents) initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "id": "13b6f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor_agent = Agent(\n",
    "    name=\"workflow_executor\",\n",
    "    model=MODEL_NAME,\n",
    "    description=\"Analyzes the workflow JSON and creates a structured step-by-step execution plan for tool agents.\",\n",
    "    instruction=(\n",
    "        \"You receive a workflow JSON object with a list of actions.\\n\"\n",
    "        \"Your job is to produce a structured PLAN listing which tool agent should execute each action.\\n\\n\"\n",
    "        \"For each action in the workflow, extract the input data and create parameters for the tool agent.\\n\"\n",
    "        \"For sheets: Extract ONLY row values from action.inputs or description and pass as:\\n\"\n",
    "        '  \"parameters\": {\"row_values\": [<list of strings>]}\\n\\n'\n",
    "        \"For each action, output an item in the plan like this:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"action_index\": <1-based index>,\\n'\n",
    "        '  \"agent\": \"slack_agent | sheets_agent | gmail_agent | calendar_agent | skipped\",\\n'\n",
    "        '  \"parameters\": {\\n'\n",
    "        '      ... only the essential parameters ...\\n'\n",
    "        '  }\\n'\n",
    "        \"}\\n\\n\"\n",
    "        \"Rules for matching:\\n\"\n",
    "        \"- Slack if type contains 'slack', 'notification', 'alert'\\n\"\n",
    "        \"- Sheets if type contains 'sheet', 'spreadsheet', 'row'\\n\"\n",
    "        \"- Gmail if type contains 'email', 'gmail', 'mail'\\n\"\n",
    "        \"- Calendar if type contains 'calendar', 'event', 'schedule'\\n\"\n",
    "        \"- Otherwise mark as skipped\\n\\n\"\n",
    "        \"Return ONLY this JSON structure:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"plan\": [... list of tool call definitions ...],\\n'\n",
    "        '  \"simulation\": {\\n'\n",
    "        '    \"workflow_name\": \"<name>\",\\n'\n",
    "        '    \"total_steps\": <count>,\\n'\n",
    "        '    \"completed_steps\": <count>,\\n'\n",
    "        '    \"status\": \"completed\",\\n'\n",
    "        '    \"log\": []\\n'\n",
    "        '  },\\n'\n",
    "        '  \"summary\": \"<human friendly short summary>\"\\n'\n",
    "        \"}\\n\"\n",
    "        \"Do not wrap response in quotes or code fences. Output ONLY JSON.\"\n",
    "    ),\n",
    ")\n",
    "# // ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "id": "2249bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Runner for executor agent ===\n",
    "executor_runner = Runner(\n",
    "    agent=executor_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "id": "14852047",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def execute_action_plan(plan):\n",
    "    results = []\n",
    "\n",
    "    for step in plan:\n",
    "        agent_name = step.get(\"agent\")\n",
    "        params = step.get(\"parameters\", {})\n",
    "        idx = step.get(\"action_index\", None)\n",
    "\n",
    "        if agent_name == \"slack_agent\":\n",
    "            resp = await slack_runner.run_debug(json.dumps(params), verbose=False)\n",
    "        elif agent_name == \"sheets_agent\":\n",
    "            resp = await sheets_runner.run_debug(json.dumps(params), verbose=False)\n",
    "        elif agent_name == \"gmail_agent\":\n",
    "            resp = await gmail_runner.run_debug(json.dumps(params), verbose=False)\n",
    "        elif agent_name == \"calendar_agent\":\n",
    "            resp = await calendar_runner.run_debug(json.dumps(params), verbose=False)\n",
    "        else:\n",
    "            results.append({\n",
    "                \"action_index\": idx,\n",
    "                \"agent\": agent_name,\n",
    "                \"result\": {\"status\": \"skipped_no_matching_agent\"},\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Parse the response properly\n",
    "        try:\n",
    "            tool_result = parse_json_output(resp)\n",
    "        except Exception as e:\n",
    "            tool_result = {\"error\": str(e), \"raw_response\": str(resp)}\n",
    "\n",
    "        results.append({\n",
    "            \"action_index\": idx,\n",
    "            \"agent\": agent_name,\n",
    "            \"result\": tool_result,\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "id": "20324c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "def parse_json_output(raw):\n",
    "    \"\"\"Robust JSON extraction for ADK responses.\"\"\"\n",
    "    import json\n",
    "    import re\n",
    "    from json.decoder import JSONDecodeError\n",
    "\n",
    "    # If list â†’ try to extract meaningful content from events first\n",
    "    if isinstance(raw, list):\n",
    "        # 1) Prefer function_response dicts (tools)\n",
    "        for ev in raw:\n",
    "            try:\n",
    "                parts = getattr(ev, \"content\").parts\n",
    "            except Exception:\n",
    "                parts = None\n",
    "            if not parts:\n",
    "                continue\n",
    "            for part in parts:\n",
    "                if hasattr(part, \"function_response\") and part.function_response:\n",
    "                    resp = getattr(part.function_response, \"response\", None)\n",
    "                    if isinstance(resp, dict):\n",
    "                        return resp\n",
    "                    # if it's a primitive or list, return as-is\n",
    "                    return resp\n",
    "        # 2) Next prefer any text produced by the model\n",
    "        texts = []\n",
    "        for ev in raw:\n",
    "            try:\n",
    "                parts = getattr(ev, \"content\").parts\n",
    "            except Exception:\n",
    "                parts = None\n",
    "            if not parts:\n",
    "                continue\n",
    "            for part in parts:\n",
    "                if hasattr(part, \"text\") and part.text:\n",
    "                    texts.append(part.text)\n",
    "        if texts:\n",
    "            # join multiple text parts into a single string\n",
    "            return \"\\n\".join(texts)\n",
    "\n",
    "        # 3) Fallback to trying each item recursively\n",
    "        for item in raw:\n",
    "            try:\n",
    "                return parse_json_output(item)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        raise ValueError(f\"No valid JSON found in list: {raw}\")\n",
    "\n",
    "    # Handle ADK Event object (single event)\n",
    "    if hasattr(raw, \"content\") and hasattr(raw.content, \"parts\"):\n",
    "        parts = raw.content.parts\n",
    "        # If part is a function_response, return its response dict\n",
    "        for part in parts:\n",
    "            if hasattr(part, \"function_response\") and part.function_response:\n",
    "                resp = getattr(part.function_response, \"response\", None)\n",
    "                if isinstance(resp, dict):\n",
    "                    return resp\n",
    "                return resp\n",
    "        # If part has text, use combined text\n",
    "        texts = [p.text for p in parts if hasattr(p, \"text\") and p.text]\n",
    "        if texts:\n",
    "            raw = \"\\n\".join(texts)\n",
    "        else:\n",
    "            # If first part is a function_call (no text), try to use its args as hint\n",
    "            first = parts[0]\n",
    "            if hasattr(first, \"function_call\") and getattr(first, \"function_call\"):\n",
    "                # return a representation of the call or empty string\n",
    "                fc = first.function_call\n",
    "                try:\n",
    "                    return getattr(fc, \"args\", None) or getattr(fc, \"payload\", None) or \"\"\n",
    "                except Exception:\n",
    "                    return \"\"\n",
    "\n",
    "    # Normalize content objects\n",
    "    elif hasattr(raw, \"text\"):\n",
    "        raw = raw.text\n",
    "\n",
    "    elif hasattr(raw, \"parts\") and raw.parts:\n",
    "        raw = raw.parts[0].text\n",
    "\n",
    "    elif hasattr(raw, \"data\"):\n",
    "        raw = raw.data\n",
    "\n",
    "    # If list (again) â†’ parse first meaningful element\n",
    "    if isinstance(raw, list):\n",
    "        for item in raw:\n",
    "            try:\n",
    "                return parse_json_output(item)\n",
    "            except Exception:\n",
    "                continue\n",
    "        raise ValueError(f\"No valid JSON found in list: {raw}\")\n",
    "\n",
    "    # If dict â†’ return directly\n",
    "    if isinstance(raw, dict):\n",
    "        return raw\n",
    "\n",
    "    if not isinstance(raw, str):\n",
    "        raise ValueError(f\"Unsupported type: {type(raw).__name__}\")\n",
    "\n",
    "    txt = raw.strip()\n",
    "\n",
    "    # Remove markdown fencing\n",
    "    if txt.startswith(\"```\"):\n",
    "        txt = txt.strip(\"`\")\n",
    "        if txt.startswith(\"json\"):\n",
    "            parts = txt.split(\"\\n\", 1)\n",
    "            txt = parts[1] if len(parts) > 1 else \"\"\n",
    "\n",
    "    # Attempt direct JSON\n",
    "    try:\n",
    "        return json.loads(txt)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Attempt to extract JSON substring\n",
    "    match = re.search(r\"\\{[\\s\\S]*\\}\", txt)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group(0))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # If still failing, return the raw text instead of raising where appropriate\n",
    "    # (caller can decide how to handle plain text responses)\n",
    "    return txt\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "id": "6115a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "async def run_flowgenie(user_prompt: str):\n",
    "\n",
    "    # ---- Memory: detect store or recall intent ----\n",
    "    store_pattern = r\"(remember that|save this|note that|store this)\"\n",
    "    recall_pattern = r\"(what did i say earlier|what is my|who did i say|remind me|recall)\"\n",
    "\n",
    "    # FETCH current session\n",
    "    session = await session_service.get_session(\n",
    "        app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID\n",
    "    )\n",
    "\n",
    "    # --- Dynamic automatic fact capture (e.g. \"my onboarding manager is Rohan\") ---\n",
    "    # BEFORE checking explicit patterns, capture any \"my X is Y\" statements\n",
    "    fact_match = re.search(\n",
    "        r\"\\bmy\\s+([a-zA-Z ]{2,40}?)\\s+(?:is|'s|are)\\s+([A-Z][\\w' \\-]{1,80})\",\n",
    "        user_prompt,\n",
    "        re.IGNORECASE,\n",
    "    )\n",
    "    if fact_match:\n",
    "        subject = fact_match.group(1).strip()\n",
    "        value = fact_match.group(2).strip()\n",
    "        entry = f\"my {subject} is {value}\"\n",
    "        session.state.setdefault(\"memory_entries\", [])\n",
    "        session.state[\"memory_entries\"].append(entry)\n",
    "        # Persist via memory service\n",
    "        await memory_service.add_session_to_memory(session)\n",
    "        # Notebook-level compatibility index\n",
    "        MEMORY_ENTRIES.setdefault(USER_ID, []).append(entry)\n",
    "        return {\n",
    "            \"memory_saved\": True,\n",
    "            \"stored_entry\": entry,\n",
    "            \"total_entries\": len(session.state[\"memory_entries\"]),\n",
    "        }\n",
    "\n",
    "    # 1ï¸âƒ£ STORE MEMORY (explicit \"remember that / note that\")\n",
    "    if re.search(store_pattern, user_prompt, re.IGNORECASE):\n",
    "        session.state.setdefault(\"memory_entries\", [])\n",
    "        session.state[\"memory_entries\"].append(user_prompt)\n",
    "\n",
    "        # Persist via memory service (InMemorySessionService has no save_session())\n",
    "        await memory_service.add_session_to_memory(session)\n",
    "\n",
    "        # Also add a cleaned entry to the notebook-level MEMORY_ENTRIES so\n",
    "        # simple_load_memory/load_memory tools can return it on recall.\n",
    "        cleaned = re.sub(store_pattern, \"\", user_prompt, flags=re.IGNORECASE).strip(\" .\\\"'\")\n",
    "        MEMORY_ENTRIES.setdefault(USER_ID, []).append(cleaned)\n",
    "\n",
    "        return {\n",
    "            \"memory_saved\": True,\n",
    "            \"stored_entry\": cleaned,\n",
    "            \"total_entries\": len(session.state[\"memory_entries\"])\n",
    "        }\n",
    "\n",
    "    # 2ï¸âƒ£ RECALL MEMORY\n",
    "        # 2ï¸âƒ£ RECALL MEMORY\n",
    "    if re.search(recall_pattern, user_prompt, re.IGNORECASE):\n",
    "        # Use the notebook-level compatibility index\n",
    "        memories = MEMORY_ENTRIES.get(USER_ID, [])\n",
    "        \n",
    "        # Extract the subject being asked about (e.g., \"work\" from \"What is my work?\")\n",
    "        subject_match = re.search(r\"(?:what is my|who is my|what did i say about)\\s+(\\w+)\", user_prompt, re.IGNORECASE)\n",
    "        \n",
    "        if subject_match and memories:\n",
    "            subject = subject_match.group(1).lower()\n",
    "            # Only return memories that mention the specific subject\n",
    "            matches = [m for m in memories if subject in m.lower()]\n",
    "            found = matches if matches else [\"No memory found for that topic\"]\n",
    "        else:\n",
    "            # Fallback: return all memories if no specific subject\n",
    "            found = memories if memories else [\"No memory found yet\"]\n",
    "        \n",
    "        return {\n",
    "            \"memory_recall\": found\n",
    "        }\n",
    "# ...existing code...\n",
    "    # Step 1 â€” Planning\n",
    "    plan_resp = await planner_runner.run_debug(user_prompt, verbose=True)\n",
    "    workflow = parse_json_output(plan_resp)\n",
    "\n",
    "    # Step 2 â€” Evaluation\n",
    "    eval_resp = await evaluator_runner.run_debug(json.dumps(workflow), verbose=True)\n",
    "    evaluation = parse_json_output(eval_resp)\n",
    "\n",
    "    # Step 3 â€” Executor generates a tool-call PLAN (not execution yet)\n",
    "        # Step 3 â€” Executor generates a tool-call PLAN (not execution yet)\n",
    "    exec_resp = await executor_runner.run_debug(json.dumps(workflow), verbose=True)\n",
    "    exec_obj = parse_json_output(exec_resp)\n",
    "\n",
    "    # Safety: if exec_obj is a string, try to parse it as JSON\n",
    "    if isinstance(exec_obj, str):\n",
    "        try:\n",
    "            exec_obj = json.loads(exec_obj)\n",
    "        except Exception:\n",
    "            exec_obj = {\"plan\": [], \"simulation\": {}, \"summary\": exec_obj}\n",
    "\n",
    "    # Tool call list + simulation results\n",
    "    action_plan = exec_obj.get(\"plan\", [])\n",
    "    simulation = exec_obj.get(\"simulation\")\n",
    "\n",
    "    # Step 4 â€” Execute tool plan (A2A actions via router)\n",
    "    tool_results = await execute_action_plan(action_plan)\n",
    "    \n",
    "    # Save final session state into long-term memory\n",
    "    completed = await session_service.get_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n",
    "    await memory_service.add_session_to_memory(completed)\n",
    "\n",
    "    return {\n",
    "        \"workflow\": workflow,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"action_plan\": action_plan,\n",
    "        \"action_results\": tool_results,\n",
    "        \"simulation\": simulation,\n",
    "        \"summary\": exec_obj.get(\"summary\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "id": "e316531c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > I work asa a software engineer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflow_planner > [Calling tool: simple_load_memory({'payload': {'query': 'software engineer'}})]\n",
      "workflow_planner > [Tool result: {'memories': []}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Event from an unknown agent: workflow_planner, event id: 8bf75887-e72e-4847-85a3-212714c18a4a\n",
      "Event from an unknown agent: workflow_planner, event id: 0993ac4b-3211-4993-ad44-18ae68ccdbe3\n",
      "Event from an unknown agent: workflow_planner, event id: 71cdd35f-cfd3-40d5-be59-a883ebfe6f37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflow_planner > I understand. Is there anything specific you'd like to automate related to your work as a software engineer? For example, are you looking to automate code testing, deployments, or perhaps manage your tasks? Let me know what you have in mind!\n",
      "\n",
      " ### Continue session: debug_session_id\n",
      "\n",
      "User > {\"memories\": []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Event from an unknown agent: workflow_evaluator, event id: 8c6e0646-8905-498b-8c56-91046cddd896\n",
      "Event from an unknown agent: workflow_planner, event id: 8bf75887-e72e-4847-85a3-212714c18a4a\n",
      "Event from an unknown agent: workflow_planner, event id: 0993ac4b-3211-4993-ad44-18ae68ccdbe3\n",
      "Event from an unknown agent: workflow_planner, event id: 71cdd35f-cfd3-40d5-be59-a883ebfe6f37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflow_evaluator > I'm an AI assistant, and I don't have personal experiences or a job title like \"software engineer.\" My purpose is to help you with your tasks by processing information and responding to your requests.\n",
      "\n",
      "It seems like you might be interacting with a system that has a memory feature. The logs you provided show that the `workflow_evaluator` tool was called to evaluate a workflow. This tool is designed to assess the quality, safety, and completeness of automated workflows.\n",
      "\n",
      "If you have a specific workflow you'd like me to evaluate, please provide the details! I can help you check for:\n",
      "\n",
      "*   **Clarity of the trigger:** Is it obvious what starts the workflow?\n",
      "*   **Completeness of actions:** Does the workflow do everything it's supposed to?\n",
      "*   **Edge cases and failure modes:** What happens if something unexpected occurs?\n",
      "*   **Privacy or safety concerns:** Are there any risks involved?\n",
      "\n",
      "I can then provide a JSON object with an overall score, a verdict (ACCEPT or IMPROVE), strengths, risks, and suggested changes.\n",
      "\n",
      " ### Continue session: debug_session_id\n",
      "\n",
      "User > {\"memories\": []}\n",
      "workflow_executor > {\n",
      "  \"plan\": [],\n",
      "  \"simulation\": {\n",
      "    \"workflow_name\": \"software_engineer_context\",\n",
      "    \"total_steps\": 0,\n",
      "    \"completed_steps\": 0,\n",
      "    \"status\": \"completed\",\n",
      "    \"log\": [\n",
      "      \"No actions found in the workflow.\"\n",
      "    ]\n",
      "  },\n",
      "  \"summary\": \"The workflow does not contain any executable actions. It seems to be a contextual setup or a misunderstanding in the previous turn, as the provided logs indicate that the user's role as a 'software engineer' was discussed but no specific workflow actions were defined.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'workflow': {'memories': []},\n",
       " 'evaluation': 'I\\'m an AI assistant, and I don\\'t have personal experiences or a job title like \"software engineer.\" My purpose is to help you with your tasks by processing information and responding to your requests.\\n\\nIt seems like you might be interacting with a system that has a memory feature. The logs you provided show that the `workflow_evaluator` tool was called to evaluate a workflow. This tool is designed to assess the quality, safety, and completeness of automated workflows.\\n\\nIf you have a specific workflow you\\'d like me to evaluate, please provide the details! I can help you check for:\\n\\n*   **Clarity of the trigger:** Is it obvious what starts the workflow?\\n*   **Completeness of actions:** Does the workflow do everything it\\'s supposed to?\\n*   **Edge cases and failure modes:** What happens if something unexpected occurs?\\n*   **Privacy or safety concerns:** Are there any risks involved?\\n\\nI can then provide a JSON object with an overall score, a verdict (ACCEPT or IMPROVE), strengths, risks, and suggested changes.',\n",
       " 'action_plan': [],\n",
       " 'action_results': [],\n",
       " 'simulation': {'workflow_name': 'software_engineer_context',\n",
       "  'total_steps': 0,\n",
       "  'completed_steps': 0,\n",
       "  'status': 'completed',\n",
       "  'log': ['No actions found in the workflow.']},\n",
       " 'summary': \"The workflow does not contain any executable actions. It seems to be a contextual setup or a misunderstanding in the previous turn, as the provided logs indicate that the user's role as a 'software engineer' was discussed but no specific workflow actions were defined.\"}"
      ]
     },
     "execution_count": 1139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await run_flowgenie(\"I work asa a software engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "id": "ea8365eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory_recall': ['No memory found yet']}"
      ]
     },
     "execution_count": 1140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await run_flowgenie(\"WHat is my work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "id": "119d2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- CORE FLOWGENIE TEST ---\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# add a row to my spreadsheet with:\n",
    "# Ticket ID 0012, Customer Rajesh, Subject Login Issue, Description Unable to log in,\n",
    "# and send a Slack notification to #new-channel saying:\n",
    "# 'New ticket from Rajesh about Login Issue'.\n",
    "# Also email me a summary.\n",
    "# \"\"\"\n",
    "\n",
    "# result = await run_flowgenie(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "id": "bfe26e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ MCP extension documented for future deployment.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: MCP requires an external MCP tool server; Kaggle cannot host one.\n",
    "# This stub demonstrates how FlowGenie can be extended with MCP:\n",
    "\n",
    "\"\"\"\n",
    "from google.adk.tools.mcp_tool import McpToolset\n",
    "\n",
    "mcp_tools = McpToolset.from_config(\n",
    "    name=\"crm_mcp\",\n",
    "    description=\"Internal CRM ticketing toolset via MCP\",\n",
    "    config_path=\"mcp/enterprise_crm.json\"\n",
    ")\n",
    "\n",
    "mcp_agent = Agent(\n",
    "    name=\"mcp_agent\",\n",
    "    model=MODEL_NAME,\n",
    "    instruction=\"Call MCP tools as needed and summarize results.\",\n",
    "    tools=[mcp_tools],\n",
    ")\n",
    "\"\"\"\n",
    "print(\"ðŸ“Œ MCP extension documented for future deployment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "id": "39df4e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohttp==3.9.5Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached aiohttp-3.9.5-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp==3.9.5)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp==3.9.5)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp==3.9.5)\n",
      "  Using cached frozenlist-1.8.0-cp312-cp312-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp==3.9.5)\n",
      "  Using cached multidict-6.7.0-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp==3.9.5)\n",
      "  Using cached yarl-1.22.0-cp312-cp312-win_amd64.whl.metadata (77 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.0->aiohttp==3.9.5)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting propcache>=0.2.1 (from yarl<2.0,>=1.0->aiohttp==3.9.5)\n",
      "  Using cached propcache-0.4.1-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting typing-extensions>=4.2 (from aiosignal>=1.1.2->aiohttp==3.9.5)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Using cached aiohttp-3.9.5-cp312-cp312-win_amd64.whl (369 kB)\n",
      "Using cached multidict-6.7.0-cp312-cp312-win_amd64.whl (46 kB)\n",
      "Using cached yarl-1.22.0-cp312-cp312-win_amd64.whl (87 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached frozenlist-1.8.0-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached propcache-0.4.1-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: typing-extensions, propcache, multidict, idna, frozenlist, attrs, yarl, aiosignal, aiohttp\n",
      "\n",
      "  Attempting uninstall: typing-extensions\n",
      "\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "  Attempting uninstall: propcache\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "    Found existing installation: propcache 0.4.1\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "    Uninstalling propcache-0.4.1:\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "      Successfully uninstalled propcache-0.4.1\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "  Attempting uninstall: multidict\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "    Found existing installation: multidict 6.7.0\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   -------- ------------------------------- 2/9 [multidict]\n",
      "    Uninstalling multidict-6.7.0:\n",
      "   -------- ------------------------------- 2/9 [multidict]\n",
      "      Successfully uninstalled multidict-6.7.0\n",
      "   -------- ------------------------------- 2/9 [multidict]\n",
      "   -------- ------------------------------- 2/9 [multidict]\n",
      "   -------- ------------------------------- 2/9 [multidict]\n",
      "   -------- ------------------------------- 2/9 [multidict]\n",
      "   -------- ------------------------------- 2/9 [multidict]\n",
      "   -------- ------------------------------- 2/9 [multidict]\n",
      "   -------- ------------------------------- 2/9 [multidict]\n",
      "  Attempting uninstall: idna\n",
      "   -------- ------------------------------- 2/9 [multidict]\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "    Found existing installation: idna 3.11\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "    Uninstalling idna-3.11:\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "      Successfully uninstalled idna-3.11\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "  Attempting uninstall: frozenlist\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "    Found existing installation: frozenlist 1.8.0\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "    Uninstalling frozenlist-1.8.0:\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "      Successfully uninstalled frozenlist-1.8.0\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "  Attempting uninstall: attrs\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "    Found existing installation: attrs 25.4.0\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "    Uninstalling attrs-25.4.0:\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "      Successfully uninstalled attrs-25.4.0\n",
      "   ------------- -------------------------- 3/9 [idna]\n",
      "   ---------------------- ----------------- 5/9 [attrs]\n",
      "   ---------------------- ----------------- 5/9 [attrs]\n",
      "   ---------------------- ----------------- 5/9 [attrs]\n",
      "  Attempting uninstall: yarl\n",
      "   ---------------------- ----------------- 5/9 [attrs]\n",
      "    Found existing installation: yarl 1.22.0\n",
      "   ---------------------- ----------------- 5/9 [attrs]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "    Uninstalling yarl-1.22.0:\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "      Successfully uninstalled yarl-1.22.0\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "  Attempting uninstall: aiosignal\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "    Found existing installation: aiosignal 1.4.0\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "    Uninstalling aiosignal-1.4.0:\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "      Successfully uninstalled aiosignal-1.4.0\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "  Attempting uninstall: aiohttp\n",
      "   -------------------------- ------------- 6/9 [yarl]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "    Found existing installation: aiohttp 3.9.5\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "    Uninstalling aiohttp-3.9.5:\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "      Successfully uninstalled aiohttp-3.9.5\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ----------------------------------- ---- 8/9 [aiohttp]\n",
      "   ---------------------------------------- 9/9 [aiohttp]\n",
      "\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.4.0 attrs-25.4.0 frozenlist-1.8.0 idna-3.11 multidict-6.7.0 propcache-0.4.1 typing-extensions-4.15.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "pip install aiohttp==3.9.5 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "id": "8e7e5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Remember that my favorite CRM system is Slack.\"\n",
    "# result = await run_flowgenie(prompt)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "id": "d7c830fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = await run_flowgenie(\"Create an automation workflow using my favorite CRM.\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "id": "60794199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Add a row to my spreadsheet with: (0012, Rajesh, Login Issue, Unable to log in)\"\n",
    "# result = await run_flowgenie(prompt)\n",
    "# print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef904a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "id": "6f78a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Send a Slack notification to #new-channel now, saying Thanksss, I'm gratefulll!)\"\n",
    "# result = await run_flowgenie(prompt)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "id": "2b62a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Send an email to my Gmail saying (FlowGenie test email) with subject (Testing automations)\"\n",
    "# result = await run_flowgenie(prompt)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a1e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
